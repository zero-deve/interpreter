# tokenizer tokenize

input:
	+ str

initial state:
	+ possible tokens = all tokens
	+ token = character empty, no type

+ read character
+ find possible tokens in prev possible tokens
+ more than one possible tokens?
	+ update possible tokens
	+ continue
+ only one possible token?
	+ update possible tokens
	+ do they match perfectly?
		+ token found
	+ else
		+ continue
+ no possible tokens?
	+ unknown token
	+ reset state